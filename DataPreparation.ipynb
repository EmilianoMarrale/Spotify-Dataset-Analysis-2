{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "import ast\n",
    "import os\n",
    "from sktime.transformations.series.detrend import Detrender\n",
    "from sktime.transformations.series.detrend import Deseasonalizer\n",
    "from statsmodels.tsa.stattools import adfuller, kpss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T20:21:43.270486Z",
     "start_time": "2024-04-12T20:21:43.194831Z"
    }
   },
   "id": "ebd37c16f07a267",
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "artists_dataset = pd.read_csv('dataset/tabular/artists.csv')\n",
    "tracks_dataset = pd.read_csv('dataset/tabular/tracks.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Artists Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "526a367367eca526"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dropping rows with NaN and duplicated lines from artists dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ad3d709d5282ef6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Drop the rows with missing values\n",
    "artists_dataset = artists_dataset.dropna()\n",
    "# Drop the duplicated rows\n",
    "artists_dataset = artists_dataset.drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bcc9019bc65f149b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Drop all the artists with same name and same genres\n",
    "artists_dataset = artists_dataset.sort_values('popularity', ascending=False).drop_duplicates(['name', 'genres'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2cacc6e06aad27f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tracks Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "146288a4369bdf28"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Aggregated all rows with duplicated 'id' values into a single row, keeping the unique genres in a list. Then dropped the duplicated rows from the original dataset and added the aggregated rows.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "191b0cfaeda7ee35"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "merged_df = tracks_dataset.groupby('id')['genre'].agg(list)\n",
    "df_merged = pd.merge(tracks_dataset, merged_df, on='id', how='left')\n",
    "\n",
    "# Find the indices of the rows with the highest popularity within each group (ID)\n",
    "indices_to_keep = df_merged.groupby('id')['popularity'].idxmax()\n",
    "# Filter the dataframe to keep only the rows with the highest popularity within each group\n",
    "tracks_dataset = df_merged.loc[indices_to_keep]\n",
    "tracks_dataset.rename(columns={'genre_y': 'genre'}, inplace=True)\n",
    "tracks_dataset = tracks_dataset.drop(columns=['genre_x'])\n",
    "# Display the resulting dataframe\n",
    "tracks_dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "70c084b8e61512f0",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e21777d3c5fee6fc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Handling songs with duplicated names"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b64f6e5d787f10c5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Drop all the duplicates rows with same 'name' and 'artists' values, and keep only the row with the highest popularity\n",
    "tracks_dataset = tracks_dataset.sort_values('popularity', ascending=False).drop_duplicates(['name', 'artists'])\n",
    "# Display the resulting dataframe\n",
    "tracks_dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b45cb1e33ebd06",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating 3 new columns: 'release_year', 'release_month', 'release_day' from the 'release_date' column"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59e90586049e8ad2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Extract year, month, and day from 'album_release_date'\n",
    "# If 'album_release_date' is in YYYY-MM format, the day will be set as NaN\n",
    "\n",
    "# First, ensure 'album_release_date' is a string to safely apply string operations\n",
    "tracks_dataset['album_release_date'] = tracks_dataset['album_release_date'].astype(str)\n",
    "\n",
    "# Split 'album_release_date' into year, month, and day\n",
    "tracks_dataset['year'] = tracks_dataset['album_release_date'].apply(lambda x: x.split('-')[0])\n",
    "tracks_dataset['month'] = tracks_dataset['album_release_date'].apply(lambda x: x.split('-')[1] if len(x.split('-')) > 1 else 'NaN')\n",
    "tracks_dataset['day'] = tracks_dataset['album_release_date'].apply(lambda x: x.split('-')[2] if len(x.split('-')) > 2 else 'NaN')\n",
    "\n",
    "# Display the first few rows to verify the new columns\n",
    "tracks_dataset[['album_release_date', 'year', 'month', 'day']]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ded246a9f4194978",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dropping columns track_number, disc_number, album_type, album_total_tracks "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2fb9c7050214b9f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Drop the columns 'track_number', 'disc_number', 'album_type', 'album_total_tracks'\n",
    "tracks_dataset = tracks_dataset.drop(columns=['track_number', 'disc_number', 'album_type', 'album_total_tracks', 'album_release_date_precision', 'album_release_date'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e6d9de0ebc9f265",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Export the cleaned datasets to CSV files\n",
    "artists_dataset.to_csv('dataset/tabular/artists_cleaned.csv', index=False)\n",
    "tracks_dataset.to_csv('dataset/tabular/tracks_cleaned.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b1424d7a78cd2b0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c12de8b15446cf13",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Time Series Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c225c0199a8d683a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "LOADING THE DATASET"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f08f116040f1b1e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def load_npy(filename):\n",
    "    return np.load(filename)\n",
    "\n",
    "\n",
    "dir_path = 'dataset/time_series/'\n",
    "len_threshold = 1280\n",
    "X, y, ids = [], [], []\n",
    "\n",
    "for file in os.listdir(dir_path):\n",
    "    if os.path.splitext(file)[1] != '.npy':\n",
    "        continue\n",
    "\n",
    "    split = file.split(\"_\")\n",
    "    ids.append(split[0])  # track_id\n",
    "    y.append(split[1][:-4])  # genre\n",
    "    ts = load_npy(dir_path + file)\n",
    "\n",
    "    if len(ts) > len_threshold:\n",
    "        ts = ts[0:len_threshold]\n",
    "    else:\n",
    "        # pad = [np.mean(ts[:-5])] * (len_threshold-len(ts)) #Â fill by mean value of last n observations\n",
    "        pad = [ts[-1]] * (len_threshold - len(ts))  # fill with last observation\n",
    "        ts = np.append(ts, pad)\n",
    "\n",
    "    X.append([ts])\n",
    "\n",
    "X, y, ids = np.array(X), np.array(y), np.array(ids)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T20:15:40.435983Z",
     "start_time": "2024-04-12T20:15:39.397483Z"
    }
   },
   "id": "6fb3b55cbeccc215",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(X[0])\n",
    "print(y[0])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2dd0894c5bf4a431",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X[0][-1]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c514675cc2a6d04f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ts = pd.Series(X[0,-1].T)\n",
    "plt.plot(ts)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "48b14d857f098c1d",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Performing offset translation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5cfbeac6084deebe"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for i in range(len(X)):\n",
    "    X[i] = X[i] - X[i].mean() #Offset translation"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T20:15:41.238180Z",
     "start_time": "2024-04-12T20:15:41.192011Z"
    }
   },
   "id": "49f25cf8bcf0fe9a",
   "execution_count": 49
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Performing amplitude scaling\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b435d05e16de19fc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for i in range(len(X)):\n",
    "    X[i] = (X[i] - X[i].mean()) / X[i].std() #Amplitue scaling"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T20:15:43.187776Z",
     "start_time": "2024-04-12T20:15:43.058057Z"
    }
   },
   "id": "2b725396542dbe38",
   "execution_count": 50
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Noice removal"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5809aba2741fc9bf"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "w = 3\n",
    "for i in range(len(X)):\n",
    "    ts = pd.Series(X[i,-1].T)\n",
    "    ts.rolling(window=w).mean() # Noise (smoothing)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1428d2097e82ac24",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ts = pd.Series(X[0,-1].T)\n",
    "w = 5\n",
    "ts.rolling(window=w).mean().plot() # Noise (smoothing)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c359720a6655b53b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "prog_house_indices = [i for i, genre in enumerate(y) if genre == 'progressive-house']\n",
    "prog_house_series = [X[i] for i in prog_house_indices]\n",
    "\n",
    "if prog_house_series:\n",
    "    # Calculate the mean time series\n",
    "    prog_house_series = np.array(prog_house_series)\n",
    "    mean_series = np.mean(prog_house_series, axis=0)\n",
    "else:\n",
    "    mean_series = None\n",
    "    print(\"No progressive-house genre found.\")    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "adeb078cd2048aca",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Time series of 'progressive-house' genre with the trend\n",
    "ts = pd.Series(mean_series[0].T)\n",
    "plt.plot(ts)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c85b508405dfc68",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Time series of 'progressive-house' genre without the trend\n",
    "t1 = pd.Series(mean_series[0].T)\n",
    "t1_detrended = detrender.fit_transform(t1)\n",
    "plt.plot(t1)\n",
    "plt.plot(t1_detrended)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50f8af554dd15c85",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Augmented Dickey-Fuller test:\n",
      "ADF Statistic: -4.730706966497688\n",
      "p-value: 7.365812781901537e-05\n",
      "\n",
      "Performing KPSS test:\n",
      "KPSS Statistic: 0.4223443850625584\n",
      "p-value: 0.0675239719557938\n"
     ]
    }
   ],
   "source": [
    "## Searching for trends in the time series\n",
    "def test_stationarity(timeseries):\n",
    "    print(\"Performing Augmented Dickey-Fuller test:\")\n",
    "    adf_test = adfuller(timeseries, autolag='AIC')\n",
    "    print(f\"ADF Statistic: {adf_test[0]}\")\n",
    "    print(f\"p-value: {adf_test[1]}\")\n",
    "\n",
    "    print(\"\\nPerforming KPSS test:\")\n",
    "    kpss_test = kpss(timeseries, regression='c', nlags='auto')\n",
    "    print(f\"KPSS Statistic: {kpss_test[0]}\")\n",
    "    print(f\"p-value: {kpss_test[1]}\")\n",
    "\n",
    "# Apply the test to a random sample\n",
    "sample_index = np.random.choice(len(X), replace=False)\n",
    "test_stationarity(X[sample_index][0])  # Assuming X[sample_index] is a numpy array\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-12T20:22:00.071615Z",
     "start_time": "2024-04-12T20:21:59.969380Z"
    }
   },
   "id": "bd509a4c2c1e389a",
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c05c88af14eb7120"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
