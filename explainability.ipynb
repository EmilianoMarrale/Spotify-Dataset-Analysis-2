{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-21T15:13:18.430070Z",
     "start_time": "2024-06-21T15:13:18.178846Z"
    }
   },
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sktime.classification.kernel_based import RocketClassifier\n",
    "from sktime.classification.interval_based import CanonicalIntervalForest\n",
    "from sktime.classification.dictionary_based import MUSE\n",
    "from sktime.transformations.series.sax import SAX\n",
    "from sktime.transformations.series.paa import PAA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics.pairwise import linear_kernel, polynomial_kernel, rbf_kernel\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T15:13:20.248327Z",
     "start_time": "2024-06-21T15:13:19.758719Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tracks_dataset_grouped_genres = pd.read_csv('dataset/tabular/tracks_dataset_without_outliers.csv')\n",
    "# conversion to a list\n",
    "tracks_dataset_grouped_genres['genre'] = tracks_dataset_grouped_genres['genre'].apply(lambda x: x.replace('[','').replace(']','').replace('\\'','').split(','))\n",
    "# keeping only the first genre\n",
    "tracks_dataset_grouped_genres['genre'] = tracks_dataset_grouped_genres['genre'].apply(lambda x: x[0])\n",
    "\n",
    "# dropping useless attributes from the dataset\n",
    "tracks_dataset_grouped_genres = tracks_dataset_grouped_genres.drop(columns=['id', 'name', 'artists', 'album_name', 'n_bars', 'month', 'day'])\n",
    "\n",
    "# one-hot encode explicit attribute with 0 and 1 in the same column\n",
    "tracks_dataset_grouped_genres['explicit'] = tracks_dataset_grouped_genres['explicit'].apply(lambda x: 1 if x == True else 0)\n",
    "\n",
    "# Convert to lowercase for case-insensitive matching\n",
    "tracks_dataset_grouped_genres['genre'] = tracks_dataset_grouped_genres['genre'].str.lower()\n",
    "\n",
    "# Grouping similar genres by checking if the keyword is contained in the label\n",
    "tracks_dataset_grouped_genres['genre'] = tracks_dataset_grouped_genres['genre'].apply(lambda x: 'rock' if any(kw in x for kw in ['rock', 'punk', 'alternative','garage', 'grunge', 'ska']) else x)\n",
    "tracks_dataset_grouped_genres['genre'] = tracks_dataset_grouped_genres['genre'].apply(lambda x: 'metal' if any(kw in x for kw in ['metal', 'grindcore']) else x)\n",
    "tracks_dataset_grouped_genres['genre'] = tracks_dataset_grouped_genres['genre'].apply(lambda x: 'pop' if any(kw in x for kw in ['pop', 'r&b', 'soul', 'funk', 'reggae', 'r-n-b']) else x)\n",
    "tracks_dataset_grouped_genres['genre'] = tracks_dataset_grouped_genres['genre'].apply(lambda x: 'electronic' if any(kw in x for kw in ['electronic', 'house', 'techno', 'trance','electro','dub', 'dubstep', 'industrial', 'drum-and-bass']) else x)\n",
    "tracks_dataset_grouped_genres['genre'] = tracks_dataset_grouped_genres['genre'].apply(lambda x: 'hip-hop' if any(kw in x for kw in ['hip-hop', 'rap', 'trap', 'grime']) else x)\n",
    "#tracks_dataset_grouped_genres['genre'] = tracks_dataset_grouped_genres['genre'].apply(lambda x: 'jazz' if any(kw in x for kw in ['jazz', 'blues', 'country', 'folk', 'classical']) else x)\n",
    "tracks_dataset_grouped_genres['genre'] = tracks_dataset_grouped_genres['genre'].apply(lambda x: 'national' if any(kw in x for kw in ['british', 'swedish', 'spanish', 'brazil', 'indian', 'iranian', 'german', 'french', 'turkish']) else x)\n",
    "\n",
    "# Convert back to title case for consistency\n",
    "tracks_dataset_grouped_genres['genre'] = tracks_dataset_grouped_genres['genre'].str.title()\n",
    "\n",
    "# Print unique genres to verify\n",
    "print(tracks_dataset_grouped_genres['genre'].unique())\n",
    "\n",
    "# count records in tracks_dataset_grouped_genres\n",
    "print(tracks_dataset_grouped_genres['genre'].value_counts())\n",
    "\n",
    "# remove all records with genre different from electronic, pop, national, rock, metal or jazz\n",
    "tracks_dataset_grouped_genres = tracks_dataset_grouped_genres[tracks_dataset_grouped_genres['genre'].isin(['Electronic', 'Pop', 'National', 'Rock', 'Metal'])]\n",
    "\n",
    "print(tracks_dataset_grouped_genres['genre'].value_counts())\n"
   ],
   "id": "e780f764410831d7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pop' 'Indie' 'Hip-Hop' 'Songwriter' 'Rock' 'Electronic' 'Country'\n",
      " 'Dance' 'Metal' 'Latino' 'Folk' 'Latin' 'Piano' 'Emo' 'Chill' 'National'\n",
      " 'Blues' 'Sad' 'Edm' 'Hardcore' 'Disco' 'Acoustic' 'Dancehall' 'J-Dance'\n",
      " 'Jazz' 'Ambient' 'Salsa' 'Afrobeat' 'Show-Tunes' 'Groove' 'Anime'\n",
      " 'Comedy' 'Trip-Hop' 'Children' 'New-Age' 'Disney' 'World-Music' 'Idm'\n",
      " 'Opera' 'Party' 'Mpb' 'Classical' 'Bluegrass' 'Sleep' 'Happy' 'Samba'\n",
      " 'Breakbeat' 'Pagode' 'Goth' 'J-Idol' 'Sertanejo' 'Kids' 'Club' 'Malay'\n",
      " 'Hardstyle' 'Gospel' 'Forro' 'Guitar' 'Honky-Tonk' 'Study' 'Tango'\n",
      " 'Romance']\n",
      "genre\n",
      "Electronic    9811\n",
      "Pop           9016\n",
      "National      7493\n",
      "Rock          7332\n",
      "Metal         4521\n",
      "              ... \n",
      "Dance          246\n",
      "Latin          196\n",
      "Indie          185\n",
      "Edm            139\n",
      "Latino         138\n",
      "Name: count, Length: 62, dtype: int64\n",
      "genre\n",
      "Electronic    9811\n",
      "Pop           9016\n",
      "National      7493\n",
      "Rock          7332\n",
      "Metal         4521\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T15:13:21.951963Z",
     "start_time": "2024-06-21T15:13:21.930875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# get the mapping of genres to integers\n",
    "genres = tracks_dataset_grouped_genres['genre'].unique()\n",
    "genre_to_int = {genre: i for i, genre in enumerate(genres)}\n",
    "int_to_genre = {i: genre for i, genre in enumerate(genres)}\n",
    "\n",
    "# convert genres to integers\n",
    "tracks_dataset_grouped_genres['genre'] = tracks_dataset_grouped_genres['genre'].apply(lambda x: genre_to_int[x])\n",
    "\n",
    "# Extract the features and the target where the target is the genre\n",
    "X = tracks_dataset_grouped_genres.drop(columns=['genre'])\n",
    "y = tracks_dataset_grouped_genres['genre']\n",
    "\n",
    "#Extract train and test from the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# normalize the dataset\n",
    "#scaler = StandardScaler()\n",
    "#X_train = scaler.fit_transform(X_train)\n",
    "#X_test = scaler.transform(X_test)"
   ],
   "id": "5a34b2a49c966914",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2024-06-21T10:13:54.616375Z",
     "start_time": "2024-06-21T09:19:07.913457Z"
    }
   },
   "cell_type": "code",
   "source": [
    "clf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'max_depth': [None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'min_weight_fraction_leaf': [0.0, 0.1, 0.3, 0.5],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'bootstrap': [True, False],\n",
    "    'random_state': [42],\n",
    "    'n_jobs': [-1]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=3, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)"
   ],
   "id": "14032e2889a70e6e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:542: FitFailedWarning: \n",
      "1944 fits failed out of a total of 5832.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "714 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 890, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py\", line 1344, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1230 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 890, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py\", line 1344, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan ... 0.25676209 0.25676209 0.25676209]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': False, 'criterion': 'gini', 'max_depth': None, 'max_features': 'log2', 'min_samples_leaf': 1, 'min_samples_split': 5, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'random_state': 42}\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T15:14:15.788851Z",
     "start_time": "2024-06-21T15:14:10.061494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "clf = RandomForestClassifier(n_estimators=500,\n",
    "                             criterion='gini',\n",
    "                             max_depth=None,\n",
    "                             min_samples_split=5,\n",
    "                             min_samples_leaf=1,\n",
    "                             min_weight_fraction_leaf=0.0,\n",
    "                             max_features='log2',\n",
    "                             oob_score=True,\n",
    "                             random_state=42,\n",
    "                             n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('Accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('F1-score %s' % f1_score(y_test, y_pred, average=None))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(clf.oob_score_)"
   ],
   "id": "363f45f5077ba38a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.6678454485920104\n",
      "F1-score [0.63684489 0.60631995 0.76881188 0.76735147 0.55951014]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.67      0.64      1803\n",
      "           1       0.59      0.63      0.61      1467\n",
      "           2       0.75      0.79      0.77      1962\n",
      "           3       0.77      0.76      0.77       904\n",
      "           4       0.66      0.49      0.56      1499\n",
      "\n",
      "    accuracy                           0.67      7635\n",
      "   macro avg       0.67      0.67      0.67      7635\n",
      "weighted avg       0.67      0.67      0.67      7635\n",
      "\n",
      "0.6608487785709608\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Explainability"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "deddcbaa6d59e700"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LORE"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30ef1fe9ce0cfa54"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [],
   "id": "79cfa0f42a5d5eeb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
