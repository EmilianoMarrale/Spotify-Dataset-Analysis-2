{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sktime.transformations.series.adapt import TabularToSeriesAdaptor\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "from pyts.approximation import paa as paa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sktime.classification.shapelet_based import ShapeletTransformClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tslearn.shapelets import LearningShapelets, grabocka_params_to_shapelet_size_dict\n",
    "from tslearn.utils import to_time_series_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe74d5bf2abddb06"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def load_npy(filename):\n",
    "    return np.load(filename)\n",
    "\n",
    "\n",
    "dir_path = 'cleaned_time_series/'\n",
    "len_threshold = 1280\n",
    "X, y, ids = [], [], []\n",
    "\n",
    "for file in os.listdir(dir_path):\n",
    "    if os.path.splitext(file)[1] != '.npy':\n",
    "        continue\n",
    "\n",
    "    split = file.split(\"_\")\n",
    "    ids.append(split[0])  # track_id\n",
    "    y.append(split[1][:-4])  # genre\n",
    "    ts = load_npy(dir_path + file)\n",
    "\n",
    "    if len(ts) > len_threshold:\n",
    "        ts = ts[0:len_threshold]\n",
    "    else:\n",
    "        # pad = [np.mean(ts[:-5])] * (len_threshold-len(ts)) #Â fill by mean value of last n observations\n",
    "        pad = [ts[-1]] * (len_threshold - len(ts))  # fill with last observation\n",
    "        ts = np.append(ts, pad)\n",
    "\n",
    "    X.append([ts])\n",
    "\n",
    "X, y, ids = np.array(X), np.array(y), np.array(ids)\n",
    "print(len(X))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb63a431217efde7",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classification"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc8fc69a78237da0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Encode the classes into int values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df8fe10ccd0e05f8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Encode the class labels as integers\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)\n",
    "original_labels = encoder.classes_\n",
    "\n",
    "for i, label in enumerate(original_labels):\n",
    "    print(f\"{label} -> {i}\")\n",
    "# print for each label its corresponding integer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d45a91956767df5",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6592fbeb854a0cc0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Approximate with PAA"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5920f2984078d1e3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Initialize PAA transformer\n",
    "approximator = paa.PiecewiseAggregateApproximation(window_size=4)\n",
    "\n",
    "# Apply PAA to your time series data\n",
    "X_paa = approximator.transform(X.reshape(-1, 1280))\n",
    "\n",
    "print(X_paa.shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7894e785df01bcc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_paa.reshape(-1, 1, 320), y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16f98cd4f7df070a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "scaler = TabularToSeriesAdaptor(MinMaxScaler(), fit_in_transform=True)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3052e8453183819a",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# KNN with DTW"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f6105f2c81d3fcb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## KNN with DTW distance (BINARY CLASSIFICATION TASK)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "677b360dcde844"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We required to filter the data in order to have only two classes: \"Heavy-Metal\" and \"Piano\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d937cced6bbf51e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Indices of classes \"heavy-metal\" (4) and \"piano\" (12)\n",
    "heavy_metal_indices = np.where(y == 4)[0]  # heavy-metal class index\n",
    "piano_indices = np.where(y == 12)[0]       # piano class index\n",
    "\n",
    "# Combine indices\n",
    "combined_indices = np.concatenate((heavy_metal_indices, piano_indices))\n",
    "\n",
    "# Filter X and y based on these indices\n",
    "X_filtered = X[combined_indices]\n",
    "y_filtered = y[combined_indices]\n",
    "ids_filtered = np.array(ids)[combined_indices]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b4a315f3b86db5f9",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Splitted the data again with the filtered data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e17b8e29980a5a5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X_train_binary, X_test_binary, y_train_binary, y_test_binary = train_test_split(\n",
    "    X_filtered, y_filtered, test_size=0.1, random_state=42, stratify=y_filtered\n",
    ")\n",
    "\n",
    "X_train_binary.shape, X_test_binary.shape, y_train_binary.shape, y_test_binary.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f603741b873a800a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "knn_binary = KNeighborsTimeSeriesClassifier(n_neighbors=5, distance=\"dtw\", n_jobs=-1)\n",
    "knn_binary.fit(X_train_scaled_binary, y_train_binary)\n",
    "\n",
    "y_pred_binary = knn_binary.predict(X_test_scaled_binary)\n",
    "print(accuracy_score(y_test_binary, y_pred_binary))\n",
    "print(classification_report(y_test_binary, y_pred_binary))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4fc7596fa3f2198",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "988e84eada5aee72"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## KNN with DTW distance (MULTICLASS CLASSIFICATION TASK)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "307d638565d79db4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "knn = KNeighborsTimeSeriesClassifier(n_neighbors=7, distance=\"dtw\", n_jobs=-1)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "print(accuracy_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24aa7f79f69a2e68",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# KNN with Euclidean distance"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "662174afdba22562"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## KNN with Euclidean distance (MULTICLASS CLASSIFICATION TASK)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1018e9e5bab4f7ec"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "knn = KNeighborsTimeSeriesClassifier(n_neighbors=7, distance=\"euclidean\", n_jobs=-1)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_multi = knn.predict(X_test_scaled)\n",
    "print(f'Accuracy score:{accuracy_score(y_test, y_pred_multi)}')\n",
    "print(classification_report(y_test, y_pred_multi))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "797aeefbecbeda5b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## KNN with Euclidean distance (BINARY CLASSIFICATION TASK)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84f012c57192fe5c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "knn_binary = KNeighborsTimeSeriesClassifier(n_neighbors=5, distance=\"euclidean\", n_jobs=-1)\n",
    "knn_binary.fit(X_train_scaled_binary, y_train_binary)\n",
    "\n",
    "y_pred_binary = knn_binary.predict(X_test_scaled_binary)\n",
    "print(accuracy_score(y_test_binary, y_pred_binary))\n",
    "print(classification_report(y_test_binary, y_pred_binary))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "130555ce03f0de0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Shapelets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d33edb9ba8c70f31"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## With tslearn library, using adam optimizer and Learning Shapelets algorithm"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92cad7c1874e0823"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Shapelets are subsequences that can be used to represent a class. Matrix profiles make it possibile to identify these shapelets.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d100b735362ea66"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# transform X_paa from this shape (10000, 320) to this shape (10000, 1, 320)\n",
    "X_paa = X_paa.reshape(X_paa.shape[0], 1, X_paa.shape[1])\n",
    "X_paa.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4fd8782c12618c8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_paa, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "460bb7f280d79111",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Adapt X to tslearn format\n",
    "X_train = to_time_series_dataset(X_train)\n",
    "X_test = to_time_series_dataset(X_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b67e02028ccd2be9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "scaler = TabularToSeriesAdaptor(MinMaxScaler(), fit_in_transform=True)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "250945cdf190f37c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# To work with the tslearn library, we need to reshape the data where the first dimension is the number of time series, the second dimension is the number of points in each time series, and the third dimension is the number of dimensions (in this case, 1 since we have univariate time series).\n",
    "X_train_scaled = X_train_scaled.reshape(X_train_scaled.shape[0], X_train_scaled.shape[2], 1)\n",
    "X_test_scaled = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[2], 1)\n",
    "\n",
    "X_train_scaled.shape, X_test_scaled.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6da5013701e2ca6d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "st = ShapeletTransformClassifier()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74bb5f38bdceb1ad",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "adam = Adam(learning_rate=0.001)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "835cada8af821fb5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%%time\n",
    "# We will extract 1 shapelet and align it with a time series\n",
    "shapelet_sizes = {16: 1200}\n",
    "\n",
    "\n",
    "# Define the model and fit it using the training data\n",
    "shp_clf = LearningShapelets(n_shapelets_per_size=shapelet_sizes,\n",
    "                            weight_regularizer=0.001,\n",
    "                            optimizer=adam,\n",
    "                            max_iter=2000,\n",
    "                            verbose=1,\n",
    "                            scale=False,\n",
    "                            random_state=42)\n",
    "shp_clf.fit(X_train_scaled, y_train)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c4b6faca9400a7f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Get the number of extracted shapelets, the (minimal) distances from\n",
    "# each of the timeseries to each of the shapelets, and the corresponding\n",
    "# locations (index) where the minimal distance was found\n",
    "n_shapelets = sum(shapelet_sizes.values())\n",
    "distances = shp_clf.transform(X_train_scaled)\n",
    "predicted_locations = shp_clf.locate(X_train_scaled)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d0c983597048d945"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "n_shapelets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "444aab1d8b5b815e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "distances"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5f5f5e2c8665b32"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "predicted_locations"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d812878c2b5e716e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# We can extract the shapelets from the model\n",
    "shapelets = shp_clf.shapelets_\n",
    "shapelets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d60cc5aeb083f926"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Check if the predictions are correct\n",
    "shp_clf.score(X_test_scaled, y_test)\n",
    "# classification report\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = shp_clf.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f9c615129b370de"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plotting the most important shapelet match for each time series"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6889d3f8af81b828"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "num_instances = 50\n",
    "\n",
    "# Set up the figure and subplots\n",
    "fig, axs = plt.subplots(num_instances, 1, figsize=(10, num_instances * 3))\n",
    "\n",
    "# Iterate through each instance and corresponding axes\n",
    "for idx, ax in enumerate(axs):\n",
    "    # Plot the time series        \n",
    "\n",
    "\n",
    "    ax.plot(X_train_scaled[idx].ravel(), \"r-\", label='Time Series')\n",
    "\n",
    "    # Find the shapelet with the smallest distance to the time series\n",
    "    min_dist_idx = np.argmin(distances[idx])\n",
    "\n",
    "    # Get the start position of this shapelet in the time series\n",
    "    start_pos = predicted_locations[idx, min_dist_idx]\n",
    "\n",
    "    # Extract the shapelet\n",
    "    shp = shapelets[min_dist_idx]\n",
    "\n",
    "    if start_pos != -1:  # Only plot if the shapelet matches the time series\n",
    "        # Extract the segment of the time series where the shapelet matches\n",
    "        matched_segment = X_train_scaled[idx, start_pos:start_pos + len(shp)].ravel()\n",
    "        ax.plot(range(start_pos, start_pos + len(shp)), matched_segment, \"g-\", linewidth=2, label='Shapelet Match')\n",
    "\n",
    "    # Enhance plot\n",
    "    ax.legend()\n",
    "    ax.set_title(f\"Time Series {idx + 1} with Most Important Shapelet Match\")\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(\"Value\")\n",
    "\n",
    "# Adjust layout to prevent overlapping\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65f5978a98f17344"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plotting the ts with id = x and the most important shapelet match"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5f647daae7c5f66"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Assuming X is the specific ID we're interested in\n",
    "specific_id = \"1U5HTINVvE7oSSscuD3Gjm\"\n",
    "\n",
    "# Set up the figure and subplots dynamically based on the number of instances with the specific ID\n",
    "num_instances = sum(1 for id_val in ids if id_val == specific_id)\n",
    "fig, axs = plt.subplots(num_instances, 1, figsize=(10, num_instances * 3), squeeze=False)\n",
    "\n",
    "# Counter for the number of plots created\n",
    "plot_count = 0\n",
    "\n",
    "\n",
    "# Iterate through each instance\n",
    "for idx in range(len(ids)):\n",
    "    if ids[idx] == specific_id:\n",
    "        ax = axs[plot_count, 0]  # Access the subplot for the current plot\n",
    "\n",
    "        # Plot the time series\n",
    "        ax.plot(X_train_scaled[idx].ravel().T, \"r-\", label='Time Series')\n",
    "\n",
    "        # Find the shapelet with the smallest distance to the time series\n",
    "        min_dist_idx = np.argmin(distances[idx])\n",
    "\n",
    "        # Get the start position of this shapelet in the time series\n",
    "        start_pos = predicted_locations[idx, min_dist_idx]\n",
    "\n",
    "        # Extract the shapelet\n",
    "        shp = shapelets[min_dist_idx]\n",
    "\n",
    "        if start_pos != -1:  # Only plot if the shapelet matches the time series\n",
    "            # Extract the segment of the time series where the shapelet matches\n",
    "            matched_segment = X_train_scaled[idx, start_pos:start_pos + len(shp)].ravel()\n",
    "            ax.plot(range(start_pos, start_pos + len(shp)), matched_segment, \"g-\", linewidth=2, label='Shapelet Match')\n",
    "\n",
    "        # Enhance plot\n",
    "        ax.legend()\n",
    "        ax.set_title(f\"Time Series with Most Important Shapelet Match of ID {specific_id}\")\n",
    "        ax.set_xlabel(\"Time\")\n",
    "        ax.set_ylabel(\"Value\")\n",
    "\n",
    "        # Increment the plot counter\n",
    "        plot_count += 1\n",
    "\n",
    "# Adjust layout to prevent overlapping\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c6c621a00a6093c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
